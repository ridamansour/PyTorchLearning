{
 "cells": [
  {
   "metadata": {
    "collapsed": true
   },
   "cell_type": "markdown",
   "source": [
    "# PyTorch 2 Quick Intro\n",
    "* Reference notebook - https://github.com/mrdbourke/pytorch-deep-learning/blob/main/extras/pytorch_2 intro.ipynb\n",
    "* Reference book chapter - https://www.learnpytorch.io/pytorch_2_intro/\n",
    "* PyTorch 2.0 release notes - https://pytorch.org/blog/pytorch-2.0-release/"
   ],
   "id": "aa293cac028f32b4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-11T20:42:08.609522Z",
     "start_time": "2026-02-11T20:42:08.551993Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "\n",
    "from going_modular.train import optimizer\n",
    "\n",
    "torch.__version__"
   ],
   "id": "adb68288cd3cf03a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.5.1'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 62
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-11T19:09:10.688051Z",
     "start_time": "2026-02-11T19:09:10.637753Z"
    }
   },
   "cell_type": "markdown",
   "source": "## Quick code examples",
   "id": "80102603c5212b8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Before PyTorch 2.0",
   "id": "dda217ae34724d63"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-11T20:42:08.844766Z",
     "start_time": "2026-02-11T20:42:08.624408Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "model = torchvision.models.resnet18()"
   ],
   "id": "40ac2da07d46f755",
   "outputs": [],
   "execution_count": 63
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### After PyTorch 2.0\n",
    "\n",
    "Note: some Pytorch 2.0 features may hinder the deployment of models - https://pytorch.org/get-started/pytorch-2.0/#inference-and-export"
   ],
   "id": "4bfcccefbd41ae9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-11T20:42:09.032851Z",
     "start_time": "2026-02-11T20:42:08.847850Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "model = torchvision.models.resnet18() # Note this can be any model\n",
    "compiled_model = torch.compile(model)\n",
    "\n",
    "### Training code\n",
    "\n",
    "### Testing code"
   ],
   "id": "de0f8bc4292f456c",
   "outputs": [],
   "execution_count": 64
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 1. Get GPU info\n",
    "\n",
    "Why get GPU info?\n",
    "\n",
    "Because PyTorch 2.0 features (`torch.compile()`) work best on newer NVIDIA GPUs.\n",
    "\n",
    "Well, what's a newer NVIDIA GPU?\n",
    "\n",
    "To find out if your GPU is compatiable, see NVIDIA GPU compability score - https://developer.nvidia.com/cuda-gpus\n",
    "\n",
    "If your GPU has a score of 8.0+, it can leverage *most* if not *all* of the new PyTorch 2.0 features.\n",
    "\n",
    "GPUs under 8.0 can still leverage PyTorch 2.0, however, the improvements may not be as noticeable as those with 8.0+.\n",
    "\n",
    "**Note:** If you're wondering what GPU you should use for deep learning, check out Tim Dettmers blog post \"Which GPU for deep learning?\""
   ],
   "id": "d1c3b4788c330b1f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-11T20:42:09.054419Z",
     "start_time": "2026-02-11T20:42:09.044020Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Make sure we're using a NVIDIA GPU\n",
    "if torch.cuda.is_available():\n",
    "  gpu_info = !nvidia-smi\n",
    "  gpu_info = '\\n'.join(gpu_info)\n",
    "  if gpu_info.find(\"failed\") >= 0:\n",
    "    print(\"Not connected to a GPU, to leverage the best of PyTorch 2.0, you should connect to a GPU.\")\n",
    "\n",
    "  # Get GPU name\n",
    "  gpu_name = !nvidia-smi --query-gpu=gpu_name --format=csv\n",
    "  gpu_name = gpu_name[1]\n",
    "  GPU_NAME = gpu_name.replace(\" \", \"_\") # remove underscores for easier saving\n",
    "  print(f'GPU name: {GPU_NAME}')\n",
    "\n",
    "  # Get GPU capability score\n",
    "  GPU_SCORE = torch.cuda.get_device_capability()\n",
    "  print(f\"GPU capability score: {GPU_SCORE}\")\n",
    "  if GPU_SCORE >= (8, 0):\n",
    "    print(f\"GPU score higher than or equal to (8, 0), PyTorch 2.x speedup features available.\")\n",
    "  else:\n",
    "    print(f\"GPU score lower than (8, 0), PyTorch 2.x speedup features will be limited (PyTorch 2.x speedups happen most on newer GPUs).\")\n",
    "\n",
    "  # Print GPU info\n",
    "  print(f\"GPU information:\\n{gpu_info}\")\n",
    "\n",
    "else:\n",
    "  print(\"PyTorch couldn't find a GPU, to leverage the best of PyTorch 2.0, you should connect to a GPU.\")"
   ],
   "id": "3e6ba77984f2c3e0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch couldn't find a GPU, to leverage the best of PyTorch 2.0, you should connect to a GPU.\n"
     ]
    }
   ],
   "execution_count": 65
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 1.1 Globally set devices\n",
    "\n",
    "Previously, we've set the device of our tensors/models using '.to(device)'.\n",
    "\n",
    "* `tensor.to(device)`\n",
    "* `model.to(device)`\n",
    "\n",
    "But in PyTorch 2.0, it's possible to set the device with a context manager as well as a global device - https://pytorch.org/blog/pytorch-2.0-release/#beta-torchset_default_device-and-torchdevice-as-context-manager\n",
    "\n",
    "See the docs- https://pytorch.org/tutorials/recipes/recipes/changing_default_device.html"
   ],
   "id": "b330df13abde1362"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-11T20:42:09.090680Z",
     "start_time": "2026-02-11T20:42:09.066803Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "\n",
    "# Set the device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.mps.is_available() else \"cpu\"\n",
    "\n",
    "# Set the device with context manager (requires PyTorch 2.x+)\n",
    "with torch.device(device):\n",
    "    # All tensors or PyTorch objects created in the context manager will be on the target device without using .to()\n",
    "    layer = torch.nn.Linear(20, 30)\n",
    "    print(f\"Layer weights are on device: {layer.weight.device}\")\n",
    "    print(f\"Layer creating data on device: {layer(torch.randn(128, 20)).device}\")"
   ],
   "id": "8d8a50ef4c4e880d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer weights are on device: mps:0\n",
      "Layer creating data on device: mps:0\n"
     ]
    }
   ],
   "execution_count": 66
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-11T20:42:09.155330Z",
     "start_time": "2026-02-11T20:42:09.100675Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "\n",
    "# Set the device\n",
    "# device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.mps.is_available() else \"cpu\"\n",
    "\n",
    "# Set the device globally (requires pytorch 2.x+)\n",
    "torch.set_default_device(\"cpu\")\n",
    "\n",
    "# All tensors or PyTorch objects created from here on out will be on the target device\n",
    "layer = torch.nn.Linear(20, 30)\n",
    "print(f\"Layer weights are on device: {layer.weight.device}\")\n",
    "print(f\"Layer creating data on device: {layer(torch.randn(128, 20)).device}\")"
   ],
   "id": "327df78ad402b705",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer weights are on device: cpu\n",
      "Layer creating data on device: cpu\n"
     ]
    }
   ],
   "execution_count": 67
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 2. Setting up the experiments\n",
    "\n",
    "Time to test speed!\n",
    "\n",
    "To keep things simple, we'll run 4 experiments.\n",
    "\n",
    "* Model: ResNet50 from torchvision\n",
    "Data: CIFAR10 from torchvision\n",
    "* Epochs: 5 (single run) and 3x5 (multi run)\n",
    "* Batch size: 128 (note: you may want to change this depending on the amount of memory your GPU has, this tutorial focuses on an A100)\n",
    "* Image size: 224 (note: you may want to adjust this given the amount of GPU memory you have)"
   ],
   "id": "c84dd4d96e298328"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-11T20:42:09.175585Z",
     "start_time": "2026-02-11T20:42:09.167853Z"
    }
   },
   "cell_type": "code",
   "source": "# !nvidia-smi # Currently using mps",
   "id": "43babfff60ccb505",
   "outputs": [],
   "execution_count": 68
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-11T20:42:09.371989Z",
     "start_time": "2026-02-11T20:42:09.180938Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "print (f\"PyTorch version: {torch.__version__}\")\n",
    "print (f\"TorchVision version: {torchvision.__version__}\")\n",
    "\n",
    "# Set the target device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.mps.is_available() else \"cpu\"\n",
    "print (f\"Using device: {device}\")"
   ],
   "id": "c661af8a82a1382f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.5.1\n",
      "TorchVision version: 0.20.1\n",
      "Using device: mps\n"
     ]
    }
   ],
   "execution_count": 69
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 2.1 Create model and transforms\n",
    "\n",
    "* ResNet50 from PyTorch - https://pytorch.org/vision/stable/models/generated/torchvision.models.resnet50.html#torchvision.models.ResNet50_Weights"
   ],
   "id": "52eca2657b502285"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-11T20:42:09.456167Z",
     "start_time": "2026-02-11T20:42:09.386877Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create model weights and transforms\n",
    "model_weights = torchvision.models.ResNet50_Weights.IMAGENET1K_V2 # .DEFAULT also works\n",
    "transforms = model_weights.transforms()\n",
    "\n",
    "transforms"
   ],
   "id": "410027c51fd370d5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ImageClassification(\n",
       "    crop_size=[224]\n",
       "    resize_size=[232]\n",
       "    mean=[0.485, 0.456, 0.406]\n",
       "    std=[0.229, 0.224, 0.225]\n",
       "    interpolation=InterpolationMode.BILINEAR\n",
       ")"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 70
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-11T20:42:10.342359Z",
     "start_time": "2026-02-11T20:42:09.478146Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = torchvision.models.resnet50(weights=model_weights)\n",
    "model"
   ],
   "id": "1df69efb751c6b24",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 71
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-11T20:42:10.495258Z",
     "start_time": "2026-02-11T20:42:10.410228Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Count the number of parameters in the model\n",
    "total_params = sum(\n",
    "    param.numel() for param in model.parameters() # count all parameters\n",
    "    # param.numel() for param in model.parameters() if param.reguires_grad = True # only count parameters that are trainable\n",
    ")\n",
    "total_params"
   ],
   "id": "40bcc2d66c6f9f81",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25557032"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 72
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Note:** PyTorch 2.0 *relative* speedups will be most noticeable when as much of the GPU as possible is being used. This means a larger model (more trainable parameters) may take longer to train on the whole but will relatively faster. E.g. a model with 1M parameters may take ~10 minutes to train but a model with 25M parameters may take ~20 minutes to train.",
   "id": "98e719f2f7499d7d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-11T20:42:10.518189Z",
     "start_time": "2026-02-11T20:42:10.505038Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_model (num_classes=10) :\n",
    "    \"\"\"\n",
    "    Creates a resnet50 model with transforms and returns them both.\n",
    "    :param num_classes: The number of classes in the dataset.\n",
    "    :return: The model and transforms created.\n",
    "    \"\"\"\n",
    "    model_weights = torchvision.models.ResNet50_Weights.DEFAULT\n",
    "    transforms = model_weights.transforms()\n",
    "    model = torchvision.models.resnet50(weights=model_weights)\n",
    "\n",
    "    # Adjust the head layer to suit our number of classes\n",
    "    model.fc = torch.nn.Linear(in_features=2048, out_features=num_classes)\n",
    "\n",
    "    return model, transforms"
   ],
   "id": "ca55e37fef8fd07f",
   "outputs": [],
   "execution_count": 73
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-11T20:42:11.200925Z",
     "start_time": "2026-02-11T20:42:10.519715Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model, transforms = create_model()\n",
    "transforms"
   ],
   "id": "45f68c397f39d59b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ImageClassification(\n",
       "    crop_size=[224]\n",
       "    resize_size=[232]\n",
       "    mean=[0.485, 0.456, 0.406]\n",
       "    std=[0.229, 0.224, 0.225]\n",
       "    interpolation=InterpolationMode.BILINEAR\n",
       ")"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 74
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 2.2 Speedups are most noticeable when a large portion of the GPU is being used\n",
    "\n",
    "Since modern GPUs are so *fast* at performing operations, you will often notice the majority of *relative* speedups when as much data as possible is on the GPU.\n",
    "\n",
    "In practice, you generally want to use as much of your GPU memory as possible.\n",
    "\n",
    "* Increasing the batch size - we've been using batch size 32 but for GPUs with a larger memory capacity you'll generally want to use as large as possible, e.g. 128, 256, 512, etc\n",
    "* Increasing data size - for example instead of using images that are 32x32, use 224x224 or 336x336, also you could use an increased embedding size for your data\n",
    "* Increase the model size - for example instead of using a model with 1M parameters, use a model with 10M parameters\n",
    "* Decreasing data transfer - since bandwidth costs (transferring data) will slow down a GPU (because it wants to compute on data)\n",
    "\n",
    "As a result of doing the above, your relative speedups should be better.\n",
    "\n",
    "E.g. overall training time may take longer but not linearly.\n",
    "\n",
    "Resource for learning how to improve PyTorch model speed - https://sebastianraschka.com/blog/2023/pytorch-faster.html\n",
    "\n",
    "**Note:** This concept of using as much data on the GPU as possible isn't restricted specifically to PyTorch 2.0, it applies to all versions on PyTorch and basically all models that train on GPUs."
   ],
   "id": "be8c3d31519d441"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 2.3 Checking the memory limits of our GPU",
   "id": "4ff5c03ad44532ad"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-11T20:42:11.293878Z",
     "start_time": "2026-02-11T20:42:11.235359Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Check available GPU memory and total GPU memory\n",
    "# total_free_gpu_memory, total_gpu_memory = torch.cuda.mem_get_info()\n",
    "total_free_gpu_memory = torch.mps.driver_allocated_memory()\n",
    "total_gpu_memory= torch.mps.recommended_max_memory()\n",
    "print(f\"Total free GPU memory: {round(total_free_gpu_memory * 1e-9, 3)} GB\")\n",
    "print(f\"Total GPU memory: {round(total_gpu_memory * 1e-9, 3)}\")"
   ],
   "id": "ed83a5492a83e290",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total free GPU memory: 1.042 GB\n",
      "Total GPU memory: 5.727\n"
     ]
    }
   ],
   "execution_count": 75
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "* If the GPU has 16GB+ of free memory, set batch size to 128\n",
    "* If the GPU has less than 16GB of free, set batch size to 32"
   ],
   "id": "9f0c62d6c24c0ab5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-11T20:42:11.355706Z",
     "start_time": "2026-02-11T20:42:11.306249Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Set batch size depending on amount of GPU memory\n",
    "total_free_gpu_memory_gb = round(total_free_gpu_memory * 1e-9, 3)\n",
    "if total_free_gpu_memory_gb >= 16:\n",
    "    BATCH_SIZE = 128 # Note: you could experiment with higher values here if you like.\n",
    "    IMAGE_SIZE = 224\n",
    "    print(f\"GPU memory available is {total_free_gpu_memory_gb} GB, using batch size of {BATCH_SIZE} and image size {IMAGE_SIZE}\")\n",
    "else:\n",
    "    BATCH_SIZE = 32\n",
    "    IMAGE_SIZE = 128\n",
    "    print(f\"GPU memory available is {total_free_gpu_memory_gb} GB, using batch size of {BATCH_SIZE} and image size {IMAGE_SIZE}\")"
   ],
   "id": "5f9f0e49cf353dbd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory available is 1.042 GB, using batch size of 32 and image size 128\n"
     ]
    }
   ],
   "execution_count": 76
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-11T20:42:11.419272Z",
     "start_time": "2026-02-11T20:42:11.370099Z"
    }
   },
   "cell_type": "code",
   "source": [
    "transforms.crop_size = 128\n",
    "transforms.resize_size = 128\n",
    "print (f\"Updated data transforms: \\n{transforms}\")"
   ],
   "id": "e94ee7294a8e9db4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated data transforms: \n",
      "ImageClassification(\n",
      "    crop_size=128\n",
      "    resize_size=128\n",
      "    mean=[0.485, 0.456, 0.406]\n",
      "    std=[0.229, 0.224, 0.225]\n",
      "    interpolation=InterpolationMode.BILINEAR\n",
      ")\n"
     ]
    }
   ],
   "execution_count": 77
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-11T19:59:48.957541Z",
     "start_time": "2026-02-11T19:59:48.926461Z"
    }
   },
   "cell_type": "markdown",
   "source": [
    "### 2.4 More potential speedups with TF32\n",
    "\n",
    "TF32 = TensorFloat32\n",
    "\n",
    "TesnorFloat32 = a datatype that bridges\n",
    "\n",
    "Float32 and Float16\n",
    "\n",
    "Float32 = a number is represented by 32 bytes (e.g. 010101010110011 = 7)\n",
    "\n",
    "Float16 = a number is represented by 16 bytes (e.g. 01010101 = 4)\n",
    "\n",
    "See more on precision in computing: https://en.wikipedia.org/wiki/Precision_(computer_science)\n",
    "\n",
    "What we want is:\n",
    "1. Fast model training\n",
    "2. Accurate model training\n",
    "\n",
    "TensorFloat32 = a datatype from NVIDIA which combines float32 and float16\n",
    "\n",
    "TF32 is available on Ampere GPUs+"
   ],
   "id": "1f74a7f1de35b30b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-11T20:42:11.496851Z",
     "start_time": "2026-02-11T20:42:11.423057Z"
    }
   },
   "cell_type": "code",
   "source": "# GPU_SCORE",
   "id": "43a8d64b829de686",
   "outputs": [],
   "execution_count": 78
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-11T20:42:11.512043Z",
     "start_time": "2026-02-11T20:42:11.498639Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# if GPU_SCORE >= (8, O): # check if GPU is compatible with TF32\n",
    "#     print(f\"[INFO] Using GPU with score: {GPU_SCORE}, enabling TensorFloat32\")\n",
    "#     torch.backends.cuda.matmul.allow_tf32 = True\n",
    "# else:\n",
    "#     print(f\"[INFO] Using GPU with score: {GPU_SCORE}, TensorFloat32 not available\")\n",
    "#     torch.backends.cuda.matmul.allow_tf32 = False"
   ],
   "id": "d2070e53530d7255",
   "outputs": [],
   "execution_count": 79
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 2.5 Preparing datasets\n",
    "\n",
    "As before, we discussed we're going to use CIFAR10.\n",
    "\n",
    "Homepage - https://www.cs.toronto.edu/~kriz/cifar.html\n",
    "\n",
    "We can download the dataset from torchvision -https://pytorch.org/vision/main/generated/torchvision.datasets.CIFAR10.html"
   ],
   "id": "43aa415a93ce7aea"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-11T20:42:13.793099Z",
     "start_time": "2026-02-11T20:42:11.513362Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create train and test datasets\n",
    "import torchvision\n",
    "train_dataset = torchvision.datasets.CIFAR10(root=\"data/\", # where to store data\n",
    "                                              train=True, # do we want training dataset\n",
    "                                              transform=transforms,\n",
    "                                              download=True)\n",
    "\n",
    "test_dataset = torchvision.datasets.CIFAR10(root=\"data/\",\n",
    "                                            train=False,\n",
    "                                            transform=transforms,\n",
    "                                            download=True)\n",
    "\n",
    "# Get the length of the datasets\n",
    "train_len = len(train_dataset)\n",
    "test_len = len(test_dataset)\n",
    "\n",
    "print(f\"[INFO] Train dataset length: {train_len}\")\n",
    "print(f\"[INFO] Test dataset length: {test_len}\")"
   ],
   "id": "770e5311dfe19848",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Train dataset length: 50000\n",
      "[INFO] Test dataset length: 10000\n"
     ]
    }
   ],
   "execution_count": 80
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-11T20:42:13.847260Z",
     "start_time": "2026-02-11T20:42:13.806329Z"
    }
   },
   "cell_type": "code",
   "source": "train_dataset[0][1]",
   "id": "2017933555f57195",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 81
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 2.6 Create DataLoaders\n",
    "\n",
    "Next:\n",
    "* Turn datasets into DataLoaders"
   ],
   "id": "4743e2203b3aa08f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-11T20:42:13.857407Z",
     "start_time": "2026-02-11T20:42:13.847924Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "\n",
    "NUM_WORKERS = os.cpu_count() # we want the highest number of CPU cores to load data to GPU\n",
    "\n",
    "train_dataloader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_dataloader = DataLoader(dataset=test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# Print details:\n",
    "print(f\"Train dataloader num batches: {len(train_dataloader)} of batch size: {BATCH_SIZE} \")\n",
    "print(f\"Test dataloader num batches: {len(train_dataloader)} of batch size: {BATCH_SIZE}\")\n",
    "print (f\"Using num workers to load data (more is generally better): {NUM_WORKERS} \")"
   ],
   "id": "17a293e67a349224",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataloader num batches: 1563 of batch size: 32 \n",
      "Test dataloader num batches: 1563 of batch size: 32\n",
      "Using num workers to load data (more is generally better): 8 \n"
     ]
    }
   ],
   "execution_count": 82
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 2.7 Creating training and test loops\n",
    "\n",
    "Want to create:\n",
    "* Training and test loops + a timing step for each, so we know how long our models take to train/test"
   ],
   "id": "bfbb34a6fba3acfd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-11T20:42:13.888744Z",
     "start_time": "2026-02-11T20:42:13.870065Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import time\n",
    "from tqdm.auto import tqdm\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "def train_step(epoch: int,\n",
    "               model: torch.nn.Module,\n",
    "               dataloader: torch.utils.data.DataLoader,\n",
    "               loss_fn: torch.nn.Module,\n",
    "               optimizer: torch.optim.Optimizer,\n",
    "               device: torch.device,\n",
    "               disable_progress_bar: bool = False) -> Tuple[float, float]:\n",
    "  \"\"\"Trains a PyTorch model for a single epoch.\n",
    "\n",
    "  Turns a target PyTorch model to training mode and then\n",
    "  runs through all of the required training steps (forward\n",
    "  pass, loss calculation, optimizer step).\n",
    "\n",
    "  Args:\n",
    "    model: A PyTorch model to be trained.\n",
    "    dataloader: A DataLoader instance for the model to be trained on.\n",
    "    loss_fn: A PyTorch loss function to minimize.\n",
    "    optimizer: A PyTorch optimizer to help minimize the loss function.\n",
    "    device: A target device to compute on (e.g. \"cuda\" or \"cpu\").\n",
    "\n",
    "  Returns:\n",
    "    A tuple of training loss and training accuracy metrics.\n",
    "    In the form (train_loss, train_accuracy). For example:\n",
    "\n",
    "    (0.1112, 0.8743)\n",
    "  \"\"\"\n",
    "  # Put model in train mode\n",
    "  model.train()\n",
    "  model.to(device)\n",
    "\n",
    "  # Setup train loss and train accuracy values\n",
    "  train_loss, train_acc = 0, 0\n",
    "\n",
    "  # Loop through data loader data batches\n",
    "  progress_bar = tqdm(\n",
    "        enumerate(dataloader),\n",
    "        desc=f\"Training Epoch {epoch}\",\n",
    "        total=len(dataloader),\n",
    "        disable=disable_progress_bar\n",
    "    )\n",
    "\n",
    "  for batch, (X, y) in progress_bar:\n",
    "      # Send data to target device\n",
    "      X, y = X.to(device), y.to(device)\n",
    "\n",
    "      # 1. Forward pass\n",
    "      y_pred = model(X)\n",
    "\n",
    "      # 2. Calculate  and accumulate loss\n",
    "      loss = loss_fn(y_pred, y)\n",
    "      train_loss += loss.item()\n",
    "\n",
    "      # 3. Optimizer zero grad\n",
    "      optimizer.zero_grad()\n",
    "\n",
    "      # 4. Loss backward\n",
    "      loss.backward()\n",
    "\n",
    "      # 5. Optimizer step\n",
    "      optimizer.step()\n",
    "\n",
    "      # Calculate and accumulate accuracy metrics across all batches\n",
    "      y_pred_class = torch.argmax(torch.softmax(y_pred, dim=1), dim=1)\n",
    "      train_acc += (y_pred_class == y).sum().item()/len(y_pred)\n",
    "\n",
    "      # Update progress bar\n",
    "      progress_bar.set_postfix(\n",
    "            {\n",
    "                \"train_loss\": train_loss / (batch + 1),\n",
    "                \"train_acc\": train_acc / (batch + 1),\n",
    "            }\n",
    "        )\n",
    "\n",
    "\n",
    "  # Adjust metrics to get average loss and accuracy per batch\n",
    "  train_loss = train_loss / len(dataloader)\n",
    "  train_acc = train_acc / len(dataloader)\n",
    "  return train_loss, train_acc\n",
    "\n",
    "def test_step(epoch: int,\n",
    "              model: torch.nn.Module,\n",
    "              dataloader: torch.utils.data.DataLoader,\n",
    "              loss_fn: torch.nn.Module,\n",
    "              device: torch.device,\n",
    "              disable_progress_bar: bool = False) -> Tuple[float, float]:\n",
    "  \"\"\"Tests a PyTorch model for a single epoch.\n",
    "\n",
    "  Turns a target PyTorch model to \"eval\" mode and then performs\n",
    "  a forward pass on a testing dataset.\n",
    "\n",
    "  Args:\n",
    "    model: A PyTorch model to be tested.\n",
    "    dataloader: A DataLoader instance for the model to be tested on.\n",
    "    loss_fn: A PyTorch loss function to calculate loss on the test data.\n",
    "    device: A target device to compute on (e.g. \"cuda\" or \"cpu\").\n",
    "\n",
    "  Returns:\n",
    "    A tuple of testing loss and testing accuracy metrics.\n",
    "    In the form (test_loss, test_accuracy). For example:\n",
    "\n",
    "    (0.0223, 0.8985)\n",
    "  \"\"\"\n",
    "  # Put model in eval mode\n",
    "  model.eval()\n",
    "  model.to(device)\n",
    "\n",
    "  # Setup test loss and test accuracy values\n",
    "  test_loss, test_acc = 0, 0\n",
    "\n",
    "  # Loop through data loader data batches\n",
    "  progress_bar = tqdm(\n",
    "      enumerate(dataloader),\n",
    "      desc=f\"Testing Epoch {epoch}\",\n",
    "      total=len(dataloader),\n",
    "      disable=disable_progress_bar\n",
    "  )\n",
    "\n",
    "  # Turn on inference context manager\n",
    "  with torch.no_grad(): # no_grad() required for PyTorch 2.0, I found some errors with `torch.inference_mode()`, please let me know if this is not the case\n",
    "      # Loop through DataLoader batches\n",
    "      for batch, (X, y) in progress_bar:\n",
    "          # Send data to target device\n",
    "          X, y = X.to(device), y.to(device)\n",
    "\n",
    "          # 1. Forward pass\n",
    "          test_pred_logits = model(X)\n",
    "\n",
    "          # 2. Calculate and accumulate loss\n",
    "          loss = loss_fn(test_pred_logits, y)\n",
    "          test_loss += loss.item()\n",
    "\n",
    "          # Calculate and accumulate accuracy\n",
    "          test_pred_labels = test_pred_logits.argmax(dim=1)\n",
    "          test_acc += ((test_pred_labels == y).sum().item()/len(test_pred_labels))\n",
    "\n",
    "          # Update progress bar\n",
    "          progress_bar.set_postfix(\n",
    "              {\n",
    "                  \"test_loss\": test_loss / (batch + 1),\n",
    "                  \"test_acc\": test_acc / (batch + 1),\n",
    "              }\n",
    "          )\n",
    "\n",
    "  # Adjust metrics to get average loss and accuracy per batch\n",
    "  test_loss = test_loss / len(dataloader)\n",
    "  test_acc = test_acc / len(dataloader)\n",
    "  return test_loss, test_acc\n",
    "\n",
    "def train(model: torch.nn.Module,\n",
    "          train_dataloader: torch.utils.data.DataLoader,\n",
    "          test_dataloader: torch.utils.data.DataLoader,\n",
    "          optimizer: torch.optim.Optimizer,\n",
    "          loss_fn: torch.nn.Module,\n",
    "          epochs: int,\n",
    "          device: torch.device,\n",
    "          disable_progress_bar: bool = False) -> Dict[str, List]:\n",
    "  \"\"\"Trains and tests a PyTorch model.\n",
    "\n",
    "  Passes a target PyTorch models through train_step() and test_step()\n",
    "  functions for a number of epochs, training and testing the model\n",
    "  in the same epoch loop.\n",
    "\n",
    "  Calculates, prints and stores evaluation metrics throughout.\n",
    "\n",
    "  Args:\n",
    "    model: A PyTorch model to be trained and tested.\n",
    "    train_dataloader: A DataLoader instance for the model to be trained on.\n",
    "    test_dataloader: A DataLoader instance for the model to be tested on.\n",
    "    optimizer: A PyTorch optimizer to help minimize the loss function.\n",
    "    loss_fn: A PyTorch loss function to calculate loss on both datasets.\n",
    "    epochs: An integer indicating how many epochs to train for.\n",
    "    device: A target device to compute on (e.g. \"cuda\" or \"cpu\").\n",
    "\n",
    "  Returns:\n",
    "    A dictionary of training and testing loss as well as training and\n",
    "    testing accuracy metrics. Each metric has a value in a list for\n",
    "    each epoch.\n",
    "    In the form: {train_loss: [...],\n",
    "                  train_acc: [...],\n",
    "                  test_loss: [...],\n",
    "                  test_acc: [...]}\n",
    "    For example if training for epochs=2:\n",
    "                 {train_loss: [2.0616, 1.0537],\n",
    "                  train_acc: [0.3945, 0.3945],\n",
    "                  test_loss: [1.2641, 1.5706],\n",
    "                  test_acc: [0.3400, 0.2973]}\n",
    "  \"\"\"\n",
    "  # Create empty results dictionary\n",
    "  results = {\"train_loss\": [],\n",
    "      \"train_acc\": [],\n",
    "      \"test_loss\": [],\n",
    "      \"test_acc\": [],\n",
    "      \"train_epoch_time\": [],\n",
    "      \"test_epoch_time\": []\n",
    "  }\n",
    "\n",
    "  # Loop through training and testing steps for a number of epochs\n",
    "  for epoch in tqdm(range(epochs), disable=disable_progress_bar):\n",
    "\n",
    "      # Perform training step and time it\n",
    "      train_epoch_start_time = time.time()\n",
    "      train_loss, train_acc = train_step(epoch=epoch,\n",
    "                                        model=model,\n",
    "                                        dataloader=train_dataloader,\n",
    "                                        loss_fn=loss_fn,\n",
    "                                        optimizer=optimizer,\n",
    "                                        device=device,\n",
    "                                        disable_progress_bar=disable_progress_bar)\n",
    "      train_epoch_end_time = time.time()\n",
    "      train_epoch_time = train_epoch_end_time - train_epoch_start_time\n",
    "\n",
    "      # Perform testing step and time it\n",
    "      test_epoch_start_time = time.time()\n",
    "      test_loss, test_acc = test_step(epoch=epoch,\n",
    "                                      model=model,\n",
    "                                      dataloader=test_dataloader,\n",
    "                                      loss_fn=loss_fn,\n",
    "                                      device=device,\n",
    "                                      disable_progress_bar=disable_progress_bar)\n",
    "      test_epoch_end_time = time.time()\n",
    "      test_epoch_time = test_epoch_end_time - test_epoch_start_time\n",
    "\n",
    "      # Print out what's happening\n",
    "      print(\n",
    "          f\"Epoch: {epoch+1} | \"\n",
    "          f\"train_loss: {train_loss:.4f} | \"\n",
    "          f\"train_acc: {train_acc:.4f} | \"\n",
    "          f\"test_loss: {test_loss:.4f} | \"\n",
    "          f\"test_acc: {test_acc:.4f} | \"\n",
    "          f\"train_epoch_time: {train_epoch_time:.4f} | \"\n",
    "          f\"test_epoch_time: {test_epoch_time:.4f}\"\n",
    "      )\n",
    "\n",
    "      # Update results dictionary\n",
    "      results[\"train_loss\"].append(train_loss)\n",
    "      results[\"train_acc\"].append(train_acc)\n",
    "      results[\"test_loss\"].append(test_loss)\n",
    "      results[\"test_acc\"].append(test_acc)\n",
    "      results[\"train_epoch_time\"].append(train_epoch_time)\n",
    "      results[\"test_epoch_time\"].append(test_epoch_time)\n",
    "\n",
    "  # Return the filled results at the end of the epochs\n",
    "  return results"
   ],
   "id": "a2c2bf216ed47d88",
   "outputs": [],
   "execution_count": 83
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 3. Time models across a single run\n",
    "Experiment 1: single run without `torch.compile()` for 5 epochs"
   ],
   "id": "d09c1eccbc98fa07"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 3.1 Experiment 1 - Single run, no compile",
   "id": "9119ae522147afba"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-11T20:42:13.909491Z",
     "start_time": "2026-02-11T20:42:13.901285Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Set the number of epochs\n",
    "NUM_EPOCHS = 1\n",
    "\n",
    "# Set the learning rate as a constant\n",
    "LEARNING_RATE = 0.003"
   ],
   "id": "85ef50fc396af86a",
   "outputs": [],
   "execution_count": 84
  },
  {
   "metadata": {
    "ExecuteTime": {
     "start_time": "2026-02-11T20:42:13.910064Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create model\n",
    "model, _ = create_model()\n",
    "model.to(\"mps\")\n",
    "\n",
    "# Create loss function and optimizer\n",
    "loss_fn = torch.nn.CrossEntropyLoss().to(\"mps\")\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "# Train model and track the results\n",
    "single_run_no_compile_results = train(\n",
    "    model=model,\n",
    "    train_dataloader=train_dataloader,\n",
    "    test_dataloader=test_dataloader,\n",
    "    optimizer=optimizer,\n",
    "    loss_fn=loss_fn,\n",
    "    epochs=NUM_EPOCHS,\n",
    "    device=torch.device(\"cpu\")\n",
    ")"
   ],
   "id": "c2120ea9ec67f73a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Training Epoch 0:   0%|          | 0/1563 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ac5ad9661d724f419d185fcb86f06c07"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 3.2 Experiment 2, single, using `torch.compile()`\n",
    "Same setup as experiment 1 except with the new line `torch.compile()`."
   ],
   "id": "6e607930d350730d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "device = torch.device(\"cpu\")\n",
    "\n",
    "# Create model and transforms\n",
    "model, transforms = create_model()\n",
    "model.to(device)\n",
    "\n",
    "# Create loss function and optimizer\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),\n",
    "                             lr=LEARNING_RATE)\n",
    "\n",
    "# Compile the model and time how long it takes\n",
    "compile_start_time = time.time()\n",
    "\n",
    "### New in PyTorch 2.x ###\n",
    "compiled_model = torch.compile(model)\n",
    "##########################\n",
    "\n",
    "compile_end_time = time.time()\n",
    "compile_time = compile_end_time - compile_start_time\n",
    "print(f\"Time to compile: {compile_time} | Note: The first time you compile your model, the first few epochs will be slower than subsequent runs.\")\n",
    "\n",
    "# Train the compiled model\n",
    "single_run_compile_results = train(model=compiled_model,\n",
    "                                   train_dataloader=train_dataloader,\n",
    "                                   test_dataloader=test_dataloader,\n",
    "                                   loss_fn=loss_fn,\n",
    "                                   optimizer=optimizer,\n",
    "                                   epochs=NUM_EPOCHS,\n",
    "                                   device=device)"
   ],
   "id": "fd8634acef309b32",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "single_run_no_compile_results",
   "id": "55d4a116d2a706d8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 3.3 Compare the results of experiment 1 and 2",
   "id": "ce2a30fb37b54c4a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Turn experiment results into dataframes\n",
    "import pandas as pd\n",
    "\n",
    "single_run_no_compile_results_df = pd.DataFrame (single_run_no_compile_results)\n",
    "single_run_compile_results_df = pd.DataFrame(single_run_compile_results)"
   ],
   "id": "1d35a1d1b0222703"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create filename to save the results\n",
    "DATASET_NAME = \"CIFAR10\"\n",
    "MODEL_NAME = \"ResNet50\""
   ],
   "id": "c6c82a862d4fc211"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_mean_epoch_times(non_compiled_results: pd.DataFrame,\n",
    "                          compiled_results: pd.DataFrame,\n",
    "                          multi_runs: bool=False,\n",
    "                          num_runs: int=0,\n",
    "                          save: bool=False,\n",
    "                          save_path: str=\"\",\n",
    "                          dataset_name: str=DATASET_NAME,\n",
    "                          model_name: str=MODEL_NAME,\n",
    "                          num_epochs: int=NUM_EPOCHS,\n",
    "                          image_size: int=IMAGE_SIZE,\n",
    "                          batch_size: int=BATCH_SIZE) -> plt.figure:\n",
    "\n",
    "    # Get the mean epoch times from the non-compiled models\n",
    "    mean_train_epoch_time = non_compiled_results.train_epoch_time.mean()\n",
    "    mean_test_epoch_time = non_compiled_results.test_epoch_time.mean()\n",
    "    mean_results = [mean_train_epoch_time, mean_test_epoch_time]\n",
    "\n",
    "    # Get the mean epoch times from the compiled models\n",
    "    mean_compile_train_epoch_time = compiled_results.train_epoch_time.mean()\n",
    "    mean_compile_test_epoch_time = compiled_results.test_epoch_time.mean()\n",
    "    mean_compile_results = [mean_compile_train_epoch_time, mean_compile_test_epoch_time]\n",
    "\n",
    "    # Calculate the percentage difference between the mean compile and non-compile train epoch times\n",
    "    train_epoch_time_diff = mean_compile_train_epoch_time - mean_train_epoch_time\n",
    "    train_epoch_time_diff_percent = (train_epoch_time_diff / mean_train_epoch_time) * 100\n",
    "\n",
    "    # Calculate the percentage difference between the mean compile and non-compile test epoch times\n",
    "    test_epoch_time_diff = mean_compile_test_epoch_time - mean_test_epoch_time\n",
    "    test_epoch_time_diff_percent = (test_epoch_time_diff / mean_test_epoch_time) * 100\n",
    "\n",
    "    # Print the mean difference percentages\n",
    "    print(f\"Mean train epoch time difference: {round(train_epoch_time_diff_percent, 3)}% (negative means faster)\")\n",
    "    print(f\"Mean test epoch time difference: {round(test_epoch_time_diff_percent, 3)}% (negative means faster)\")\n",
    "\n",
    "    # Create a bar plot of the mean train and test epoch time for both compiled and non-compiled models\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    width = 0.3\n",
    "    x_indicies = np.arange(len(mean_results))\n",
    "\n",
    "    plt.bar(x=x_indicies, height=mean_results, width=width, label=\"non_compiled_results\")\n",
    "    plt.bar(x=x_indicies + width, height=mean_compile_results, width=width, label=\"compiled_results\")\n",
    "    plt.xticks(x_indicies + width / 2, (\"Train Epoch\", \"Test Epoch\"))\n",
    "    plt.ylabel(\"Mean epoch time (seconds, lower is better)\")\n",
    "\n",
    "    # Create the title based on the parameters passed to the function\n",
    "    if multi_runs:\n",
    "        plt.suptitle(\"Multiple run results\")\n",
    "        plt.title(f\"GPU: {gpu_name} | Epochs: {num_epochs} ({num_runs} runs) | Data: {dataset_name} | Model: {model_name} | Image size: {image_size} | Batch size: {batch_size}\")\n",
    "    else:\n",
    "        plt.suptitle(\"Single run results\")\n",
    "        plt.title(f\"GPU: {gpu_name} | Epochs: {num_epochs} | Data: {dataset_name} | Model: {model_name} | Image size: {image_size} | Batch size: {batch_size}\")\n",
    "    plt.legend();\n",
    "\n",
    "    # Save the figure\n",
    "    if save:\n",
    "        assert save_path != \"\", \"Please specify a save path to save the model figure to via the save_path parameter.\"\n",
    "        plt.savefig(save_path)\n",
    "        print(f\"[INFO] Plot saved to {save_path}\")"
   ],
   "id": "63656a40de6e2443"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create directory for saving figures\n",
    "import os\n",
    "dir_to_save_figures_in = \"pytorch_2_results/figures/\"\n",
    "os.makedirs(dir_to_save_figures_in, exist_ok=True)\n",
    "\n",
    "# Create a save path for the single run results\n",
    "save_path_multi_run = f\"{dir_to_save_figures_in}single_run_{GPU_NAME}_{MODEL_NAME}_{DATASET_NAME}_{IMAGE_SIZE}_train_epoch_time.png\"\n",
    "print(f\"[INFO] Save path for single run results: {save_path_multi_run}\")\n",
    "\n",
    "# Plot the results and save the figures\n",
    "plot_mean_epoch_times(non_compiled_results=single_run_no_compile_results_df,\n",
    "                      compiled_results=single_run_compile_results_df,\n",
    "                      multi_runs=False,\n",
    "                      save_path=save_path_multi_run,\n",
    "                      save=True)"
   ],
   "id": "7d1202dab7e446e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 3.4 Save single run results to file with GPU details",
   "id": "4f8062c6c038f0dd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Make a directory for single_run results\n",
    "import os\n",
    "pytorch_2_results_dir = \"pytorch_2_results\"\n",
    "pytorch_2_single_run_results_dir = f\"{pytorch_2_results_dir}/single_run_results\"\n",
    "os.makedirs(pytorch_2_single_run_results_dir, exist_ok=True)\n",
    "\n",
    "# Create filenames for each of the dataframes\n",
    "save_name_for_non_compiled_results = f\"single_run_non_compiled_results_{DATASET_NAME}_{MODEL_NAME}_{GPU_NAME}.csv\"\n",
    "save_name_for_compiled_results = f\"single_run_compiled_results_{DATASET_NAME}_{MODEL_NAME}_{GPU_NAME}.csv\"\n",
    "\n",
    "# Create filepaths to save the results to\n",
    "single_run_no_compile_save_path = f\"{pytorch_2_single_run_results_dir}/{save_name_for_non_compiled_results}\"\n",
    "single_run_compile_save_path = f\"{pytorch_2_single_run_results_dir}/{save_name_for_compiled_results}\"\n",
    "print(f\"[INFO] Saving non-compiled experiment 1 results to: {single_run_no_compile_save_path}\")\n",
    "print(f\"[INFO] Saving compiled experiment 2 results to: {single_run_compile_save_path}\")\n",
    "\n",
    "# Save the results\n",
    "single_run_no_compile_results_df.to_csv(single_run_no_compile_save_path)\n",
    "single_run_compile_results_df.to_csv(single_run_compile_save_path)"
   ],
   "id": "51e6f8320eaeb0c4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 4. Time models across multiple runs\n",
    "Time for multi-run experiments!\n",
    "* Experiment 3 - 3x5 epochs without `torch.compile()`\n",
    "* Experiment 4 - 3x5 epochs with `torch.compile()`"
   ],
   "id": "e5db7e0b9407eb5f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "4cd72e1d7683bbd8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# \\# Progress updates",
   "id": "a6bf247a0ccfa5fa"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from Progress.course_progress_func import update_progress, progress_pie_chart, monthly_progress, progress_report_print\n",
    "\n",
    "update_progress(video_index=345, done=True)"
   ],
   "id": "2174985def29776e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "progress_report_print()",
   "id": "92ffe62e2e30da90",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "progress_pie_chart()",
   "id": "e1b06f946532a560",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
