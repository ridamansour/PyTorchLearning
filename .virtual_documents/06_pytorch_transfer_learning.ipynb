


import matplotlib.pyplot as plt
import torch
import torchvision
from xlwings.utils import col_name

from going_modular.train import train_dir, train_dataloader, test_dataloader, optimizer

print(torch.__version__)
print(torchvision.__version__)

from going_modular import data_setup, engine


device = torch.device("cuda" if torch.cuda.is_available() else ("mps" if torch.mps.is_available() else "cpu"))
device





import os
import zipfile

from pathlib import Path

import requests

# Setup data path
data_path = Path("data/")
image_path = data_path / "pizza_steak_sushi" # images from a subset of classes from the Food101 dataset

# If the image folder doesn't exist, download and prepare it...
if image_path.is_dir():
    print(f"{image_path} exists")
else:
    print(f"{image_path} does not exist, downloading it")
    image_path.mkdir(parents=True, exist_ok=True)
    
    # Download pizza, steak, sushi data
    with open(data_path / "pizza_steak_sushi.zip", "wb") as f:
        request = requests.get("https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip")
        f.write(request.content)

    # unzip pizza, steak, sushi data
    with zipfile.ZipFile(data_path / "pizza_steak_sushi.zip", "r") as zip_ref:
        print("Extracting pizza_steak_sushi.zip")
        zip_ref.extractall(image_path)

    # Remove .zip file
    os.remove(data_path / "pizza_steak_sushi.zip")


# Setup directory path
train_dir = image_path / "train"
test_dir = image_path / "test"

train_dir, test_dir








from torchvision import transforms
normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],
                                 std=[0.229, 0.224, 0.225])
manual_transforms = transforms.Compose([transforms.Resize((224, 224)), # resize image to 224, 224 (height x width)
                                         transforms.ToTensor (), # get images into range [0, 1]
                                         normalize]) # make sure images have the same distribution as ImageNet (where our pretrained models have been trained)|


from going_modular import data_setup
train_dataloader, test_dataloader, class_names = data_setup.create_dataloaders(
    train_dir = train_dir,
    test_dir = test_dir,
    transform = manual_transforms,
    batch_size = 32,
)
train_dataloader, test_dataloader, class_names





import torchvision
torchvision.__version__


# Get a set of pretrained model weights
weights = torchvision.models.EfficientNet_B0_Weights.DEFAULT
weights


# Get the transforms used to create our pretrained weights
auto_transforms = weights.transforms()
auto_transforms


# Create DataLoaders using automatic transforms
train_dataloader, test_dataloader, class_names = data_setup.create_dataloaders(
    train_dir = train_dir,
    test_dir = test_dir,
    transform = auto_transforms,
    batch_size = 32,
)
train_dataloader, test_dataloader, class_names











weights = torchvision.models.EfficientNet_B0_Weights.DEFAULT
model = torchvision.models.efficientnet_b0(weights=weights)
model


model.classifier





# Print with torchinfo
from torchinfo import summary

summary_args = {
    "model":model,
    "input_size":(1, 3, 224, 224), # example of [batch_size, color_channels, height, width]
    "col_names":["input_size", "output_size", "num_params", "trainable"],
    "col_width":20,
    "row_settings":["var_names"]
}
summary(**summary_args)





# Freeze all the base layers in EffNetB0
for param in model.features.parameters():
    # print(param)
    param.requires_grad = False


# Update the classifier head of our model ro suit our problem
from torch import nn

torch.manual_seed(42)
torch.mps.manual_seed(42)

model.classifier = nn.Sequential(
    nn.Dropout(p=0.2, inplace=True),
    nn.Linear(in_features=1280, out_features=len(class_names), bias=True),
).to(device)

model.classifier


summary(**summary_args)





# Define loss and optimizer
loss_fn = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=0.001)


# Import train function
from going_modular import engine

# Set the manual seeds
torch.manual_seed(42)
torch.mps.manual_seed(42)
model.to(device)

# Start the timer
from timeit import default_timer as timer
start_time = timer()
# Setup training and saving the results
results = engine.train(
    model=model,
    train_dataloader=train_dataloader,
    test_dataloader=test_dataloader,
    optimizer=optimizer,
    loss_fn=loss_fn,
    epochs=5,
    device=device,
)

# End the timer and print out how long it took
end_time = timer()
print(f"[INFO] Total training time: {end_time - start_time:.3f} seconds")





from helper_functions import plot_loss_curves
# Plot the loss curves of our model
plot_loss_curves(results)





type(.Compose([
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406],
                                 std=[0.229, 0.224, 0.225])
        ]))
transforms.


from typing import List, Tuple, Optional, Callable
from PIL import Image
from torchvision import transforms
import matplotlib.pyplot as plt

# 1. Take in a trained model
def pred_and_plot_image(model: torch.nn.Module,
                        image_path: str | Path,
                        class_names: List[str],
                        image_size: Tuple[int, int] = (224, 224),
                        transform: Optional[Callable[[Image.Image], torch.Tensor]]  = None,
                        device: torch.device = device):
    # 2. Open the image with PIL
    img = Image.open(image_path)

    # Create a transform if one doesn't exist
    if transform is None:
        transform = transforms.Compose([
            transforms.Resize((image_size[0], image_size[1])),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406],
                                 std=[0.229, 0.224, 0.225])
        ])

    ### Predict on Image ###
    # 4. Make sure the model is on the target device
    model.to(device)

    # 5. Turn on inference model and eval mode
    model.eval()
    with torch.inference_mode():
        # 6. transform the image and add an extra batch dimension
        transformed_image = transform(img).unsqueeze(dim=0) # [batch_size, c_ch, H, W]

        # 7. Make a prediction on the transformed image by passing it to the model + ensuring it's on the target device
        target_image_pred = model(transformed_image.to(device))

    # 8. Convert the model's output logits to pred probs
    target_image_pred_probs = torch.softmax(target_image_pred, dim=1)

    # 9. Convert the mode's pred probs to pred labels
    target_image_pred_label = torch.argmax(target_image_pred_probs, dim=1)

    # 10. Plot the image with image label and prob
    plt.figure()
    plt.imshow(img)
    plt.title(f"Pred: {class_names[target_image_pred_label]} | Prob: {target_image_pred_probs.max():.3f}")
    plt.axis('off')
    plt.show()


# Get a random list of image paths from the test set
import random
num_images_to_plot = 3
test_image_path_list = list(Path(test_dir).rglob("*/*.jpg"))

rand_imgs_samples = random.sample(test_image_path_list, k=num_images_to_plot)

# Make predictions on and plot the images
for img_path in rand_imgs_samples:
    pred_and_plot_image(
        model=model,
        image_path=img_path,
        class_names=class_names,
    )


test_dir





pred_and_plot_image(
    model=model,
    image_path=Path("data/04-pizza-dad.jpeg"),
    class_names=class_names,
)


from Progress.course_progress_func import update_progress, progress_pie_chart, monthly_progress, progress_report_print
update_progress(video_index=199, done=True)


progress_report_print()
