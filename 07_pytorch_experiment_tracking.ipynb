{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 07. PyTorch Experiment Tracking\n",
    "\n",
    "Machine learning is very experimental.\n",
    "\n",
    "In order to figure out which experiments are worth pursuing, that's where **experiment tracking** comes in, it helps you to figure out what doesn't work so you can figure out what **does** work.\n",
    "\n",
    "In this notebook, we're going to see an example of programmatically tracking experiments.\n",
    "\n",
    "Resources:\n",
    "* Book version of notebook: https://www.learnpytorch.io/07_pytorch_experiment_tracking/\n",
    "* Ask a question: https://github.com/mrdbourke/pytorch-deep-learning/discussions\n",
    "* Extra-curriculum: https://madewithml.com/courses/mlops/experiment-tracking/"
   ],
   "id": "b8bc2752f96edabe"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-14T18:07:50.860698Z",
     "start_time": "2025-12-14T18:07:36.776599Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from sphinx.builders.gettext import timestamp\n",
    "from torch import nn\n",
    "from torchvision import transforms\n",
    "from torchinfo import summary\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from xlwings.utils import col_name\n",
    "\n",
    "from going_modular import data_setup, engine\n",
    "from going_modular.train import train_dataloader, test_dataloader\n",
    "\n",
    "print(torch.__version__)\n",
    "print(torchvision.__version__)"
   ],
   "id": "c296b9c0199bb73e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.1\n",
      "0.20.1\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-14T18:07:51.132038Z",
     "start_time": "2025-12-14T18:07:50.877713Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Setup device agnostic code\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\" if torch.mps.is_available() else \"cpu\")\n",
    "device"
   ],
   "id": "eff5f67095c30f1b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='mps')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-14T18:07:51.149895Z",
     "start_time": "2025-12-14T18:07:51.138665Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Set seeds\n",
    "def set_seeds (seed: int=42):\n",
    "    \"\"\"\n",
    "    Sets random sets for torch operations.\n",
    "\n",
    "    Args:\n",
    "        seed (int, optional): Random seed to set. Defaults to 42.\n",
    "    \"\"\"\n",
    "    # the seed for general torch operations\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "    # Set the seed for CUDA+MPS torch operations (ones that happen on the GPU)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.mps.manual_seed(seed)"
   ],
   "id": "e13759b13f5afebf",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-14T18:07:51.176395Z",
     "start_time": "2025-12-14T18:07:51.151407Z"
    }
   },
   "cell_type": "code",
   "source": "set_seeds()",
   "id": "4e6431fcd37a019d",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 1. Get data\n",
    "\n",
    "Want to get pizza, steak, sushi images.\n",
    "\n",
    "So we can run experiments building FoodVision Mini and see which model performs best."
   ],
   "id": "adcae76b88b261d9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-14T18:07:51.908443Z",
     "start_time": "2025-12-14T18:07:51.177817Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "from typing import Optional\n",
    "\n",
    "import requests\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "def download_data(\n",
    "    source: str,\n",
    "    destination: str,\n",
    "    remove_source: bool = True,\n",
    "    chunk_size: int = 1024\n",
    ") -> Path:\n",
    "    \"\"\"Downloads a zipped dataset from source and unzips to destination.\"\"\"\n",
    "\n",
    "    data_path = Path(\"data\")\n",
    "    image_path = data_path / destination\n",
    "    data_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    if image_path.is_dir():\n",
    "        print(f\"[INFO] {image_path} directory exists, skipping download.\")\n",
    "        return image_path\n",
    "\n",
    "    print(f\"[INFO] Creating directory {image_path}...\")\n",
    "    image_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    target_file = data_path / Path(source).name\n",
    "\n",
    "    print(f\"[INFO] Downloading {target_file.name}...\")\n",
    "    response = requests.get(source, stream=True)\n",
    "    response.raise_for_status()\n",
    "\n",
    "    total_size = int(response.headers.get(\"content-length\", 0))\n",
    "\n",
    "    with open(target_file, \"wb\") as f, tqdm(\n",
    "        desc=\"Downloading\",\n",
    "        total=total_size,\n",
    "        unit=\"B\",\n",
    "        unit_scale=True,\n",
    "        unit_divisor=1024,\n",
    "    ) as pbar:\n",
    "        for chunk in response.iter_content(chunk_size=chunk_size):\n",
    "            if chunk:\n",
    "                f.write(chunk)\n",
    "                pbar.update(len(chunk))\n",
    "\n",
    "\n",
    "    print(f\"[INFO] Unzipping {target_file.name}...\")\n",
    "    with zipfile.ZipFile(target_file, \"r\") as zip_ref:\n",
    "        members = zip_ref.infolist()\n",
    "        for member in tqdm(members, desc=\"Extracting\", unit=\"file\"):\n",
    "            zip_ref.extract(member, image_path)\n",
    "\n",
    "    if remove_source:\n",
    "        target_file.unlink()\n",
    "\n",
    "    print(\"[INFO] Download and extraction complete.\")\n",
    "    return image_path\n",
    "\n",
    "\n",
    "image_path = download_data(source=\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip\",\n",
    "                           destination=\"pizza_steak_sushi\")\n",
    "image_path"
   ],
   "id": "7dc31f177819d785",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] data/pizza_steak_sushi directory exists, skipping download.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PosixPath('data/pizza_steak_sushi')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-13T12:57:12.731851Z",
     "start_time": "2025-12-13T12:57:12.678823Z"
    }
   },
   "cell_type": "markdown",
   "source": "## 2. Create Datasets and DataLoaders",
   "id": "32614c0061f07853"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 2.1 Create DataLoaders with manual transforms\n",
    "The goal with transforms is to ensure your custom data is formatted in a reproducible way as well as a way that will suit pretrained models."
   ],
   "id": "aea661e4956f9cdd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-14T18:07:52.164835Z",
     "start_time": "2025-12-14T18:07:52.115952Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Setup directories\n",
    "train_dir = image_path / \"train\"\n",
    "test_dir = image_path / \"test\"\n",
    "train_dir, test_dir"
   ],
   "id": "a771ab332a26c76d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(PosixPath('data/pizza_steak_sushi/train'),\n",
       " PosixPath('data/pizza_steak_sushi/test'))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-14T18:07:52.199631Z",
     "start_time": "2025-12-14T18:07:52.166448Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Setup ImageNet normalization levels\n",
    "# See here: https://pytorch.org/vision/0.12/models.html\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.4061], std=[0.229, 0.224, 0.225])\n",
    "\n",
    "# Create transform pipeline manually\n",
    "manual_transforms = transforms. Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    normalize\n",
    "])\n",
    "print (f\"Manually created transforms: {manual_transforms}\")\n",
    "\n",
    "# Create DataLoaders\n",
    "from going_modular import data_setup\n",
    "train_dataloader, test_dataloader, class_names = data_setup.create_dataloaders(train_dir=train_dir,\n",
    "                                                                               test_dir=test_dir,\n",
    "                                                                               train_transform=manual_transforms,\n",
    "                                                                               test_transform=manual_transforms,\n",
    "                                                                               batch_size=32)\n",
    "train_dataloader, test_dataloader, class_names"
   ],
   "id": "de637faa45e05155",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manually created transforms: Compose(\n",
      "    Resize(size=(224, 224), interpolation=bilinear, max_size=None, antialias=True)\n",
      "    ToTensor()\n",
      "    Normalize(mean=[0.485, 0.456, 0.4061], std=[0.229, 0.224, 0.225])\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<torch.utils.data.dataloader.DataLoader at 0x30514ac30>,\n",
       " <torch.utils.data.dataloader.DataLoader at 0x30461d2b0>,\n",
       " ['pizza', 'steak', 'sushi'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 2.2 Create DataLoaders using automatically created transforms\n",
    "\n",
    "The same principle applies for automatically created transforms we want our custom data in the same format as the pretrained data the model trained on."
   ],
   "id": "faa459529f16c7a0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-14T18:07:52.232264Z",
     "start_time": "2025-12-14T18:07:52.204450Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Setup dirs\n",
    "train_dir = image_path / \"train\"\n",
    "test_dir = image_path / \"test\"\n",
    "\n",
    "# Setup pretrained weights\n",
    "import torchvision\n",
    "weights = torchvision.models.EfficientNet_B0_Weights.DEFAULT # \"DEFAULT\" = best available\n",
    "\n",
    "# Get the transforms from weights (these are the transforms used to train a particular or obtain a particular set of weights)\n",
    "automatic_transforms = weights.transforms()\n",
    "print (f\"Automatically created transforms: {automatic_transforms}\")\n",
    "# Create DataLoaders\n",
    "train_dataloader, test_dataloader, class_names = data_setup.create_dataloaders(train_dir=train_dir,\n",
    "                                                                               test_dir=test_dir,\n",
    "                                                                               train_transform=automatic_transforms,\n",
    "                                                                               test_transform=automatic_transforms,\n",
    "                                                                               batch_size=32)\n",
    "train_dataloader, test_dataloader, class_names"
   ],
   "id": "6c08dabc7cdb0013",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created transforms: ImageClassification(\n",
      "    crop_size=[224]\n",
      "    resize_size=[256]\n",
      "    mean=[0.485, 0.456, 0.406]\n",
      "    std=[0.229, 0.224, 0.225]\n",
      "    interpolation=InterpolationMode.BICUBIC\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<torch.utils.data.dataloader.DataLoader at 0x3051d20f0>,\n",
       " <torch.utils.data.dataloader.DataLoader at 0x3051d21b0>,\n",
       " ['pizza', 'steak', 'sushi'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 3. Getting a pretrained model, freeze the base layers and change the classifier head",
   "id": "84617dd806234ec"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-14T18:07:52.480155Z",
     "start_time": "2025-12-14T18:07:52.232932Z"
    }
   },
   "cell_type": "code",
   "source": [
    "weights = torchvision.models.EfficientNet_B0_Weights.DEFAULT # \"DEFAULT\" = best available\n",
    "model = torchvision.models.efficientnet_b0(weights= weights).to(device)"
   ],
   "id": "5051895887231542",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-14T18:07:52.497385Z",
     "start_time": "2025-12-14T18:07:52.481169Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Freeze all base layers by setting their requires_grad attribute to False\n",
    "for param in model.features.parameters():\n",
    "    # print(param)\n",
    "    param.requires_grad = False"
   ],
   "id": "7b79496fc5f7ad63",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-14T18:07:52.506955Z",
     "start_time": "2025-12-14T18:07:52.498456Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Adjust the classifier head\n",
    "set_seeds()\n",
    "model.classifier = nn.Sequential(\n",
    "    nn.Dropout(p=0.2, inplace=True),\n",
    "    nn.Linear(in_features=1280, out_features=len(class_names), bias=True)\n",
    ").to(device)"
   ],
   "id": "2b02df0257f6d268",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-14T18:07:55.454003Z",
     "start_time": "2025-12-14T18:07:52.507574Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "summary(model,\n",
    "        input_size=(32, 3, 224, 224),\n",
    "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "        col_width=20,\n",
    "        row_settings=[\"var_names\"])"
   ],
   "id": "1a98cb5303a9b784",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "============================================================================================================================================\n",
       "Layer (type (var_name))                                      Input Shape          Output Shape         Param #              Trainable\n",
       "============================================================================================================================================\n",
       "EfficientNet (EfficientNet)                                  [32, 3, 224, 224]    [32, 3]              --                   Partial\n",
       "├─Sequential (features)                                      [32, 3, 224, 224]    [32, 1280, 7, 7]     --                   False\n",
       "│    └─Conv2dNormActivation (0)                              [32, 3, 224, 224]    [32, 32, 112, 112]   --                   False\n",
       "│    │    └─Conv2d (0)                                       [32, 3, 224, 224]    [32, 32, 112, 112]   (864)                False\n",
       "│    │    └─BatchNorm2d (1)                                  [32, 32, 112, 112]   [32, 32, 112, 112]   (64)                 False\n",
       "│    │    └─SiLU (2)                                         [32, 32, 112, 112]   [32, 32, 112, 112]   --                   --\n",
       "│    └─Sequential (1)                                        [32, 32, 112, 112]   [32, 16, 112, 112]   --                   False\n",
       "│    │    └─MBConv (0)                                       [32, 32, 112, 112]   [32, 16, 112, 112]   (1,448)              False\n",
       "│    └─Sequential (2)                                        [32, 16, 112, 112]   [32, 24, 56, 56]     --                   False\n",
       "│    │    └─MBConv (0)                                       [32, 16, 112, 112]   [32, 24, 56, 56]     (6,004)              False\n",
       "│    │    └─MBConv (1)                                       [32, 24, 56, 56]     [32, 24, 56, 56]     (10,710)             False\n",
       "│    └─Sequential (3)                                        [32, 24, 56, 56]     [32, 40, 28, 28]     --                   False\n",
       "│    │    └─MBConv (0)                                       [32, 24, 56, 56]     [32, 40, 28, 28]     (15,350)             False\n",
       "│    │    └─MBConv (1)                                       [32, 40, 28, 28]     [32, 40, 28, 28]     (31,290)             False\n",
       "│    └─Sequential (4)                                        [32, 40, 28, 28]     [32, 80, 14, 14]     --                   False\n",
       "│    │    └─MBConv (0)                                       [32, 40, 28, 28]     [32, 80, 14, 14]     (37,130)             False\n",
       "│    │    └─MBConv (1)                                       [32, 80, 14, 14]     [32, 80, 14, 14]     (102,900)            False\n",
       "│    │    └─MBConv (2)                                       [32, 80, 14, 14]     [32, 80, 14, 14]     (102,900)            False\n",
       "│    └─Sequential (5)                                        [32, 80, 14, 14]     [32, 112, 14, 14]    --                   False\n",
       "│    │    └─MBConv (0)                                       [32, 80, 14, 14]     [32, 112, 14, 14]    (126,004)            False\n",
       "│    │    └─MBConv (1)                                       [32, 112, 14, 14]    [32, 112, 14, 14]    (208,572)            False\n",
       "│    │    └─MBConv (2)                                       [32, 112, 14, 14]    [32, 112, 14, 14]    (208,572)            False\n",
       "│    └─Sequential (6)                                        [32, 112, 14, 14]    [32, 192, 7, 7]      --                   False\n",
       "│    │    └─MBConv (0)                                       [32, 112, 14, 14]    [32, 192, 7, 7]      (262,492)            False\n",
       "│    │    └─MBConv (1)                                       [32, 192, 7, 7]      [32, 192, 7, 7]      (587,952)            False\n",
       "│    │    └─MBConv (2)                                       [32, 192, 7, 7]      [32, 192, 7, 7]      (587,952)            False\n",
       "│    │    └─MBConv (3)                                       [32, 192, 7, 7]      [32, 192, 7, 7]      (587,952)            False\n",
       "│    └─Sequential (7)                                        [32, 192, 7, 7]      [32, 320, 7, 7]      --                   False\n",
       "│    │    └─MBConv (0)                                       [32, 192, 7, 7]      [32, 320, 7, 7]      (717,232)            False\n",
       "│    └─Conv2dNormActivation (8)                              [32, 320, 7, 7]      [32, 1280, 7, 7]     --                   False\n",
       "│    │    └─Conv2d (0)                                       [32, 320, 7, 7]      [32, 1280, 7, 7]     (409,600)            False\n",
       "│    │    └─BatchNorm2d (1)                                  [32, 1280, 7, 7]     [32, 1280, 7, 7]     (2,560)              False\n",
       "│    │    └─SiLU (2)                                         [32, 1280, 7, 7]     [32, 1280, 7, 7]     --                   --\n",
       "├─AdaptiveAvgPool2d (avgpool)                                [32, 1280, 7, 7]     [32, 1280, 1, 1]     --                   --\n",
       "├─Sequential (classifier)                                    [32, 1280]           [32, 3]              --                   True\n",
       "│    └─Dropout (0)                                           [32, 1280]           [32, 1280]           --                   --\n",
       "│    └─Linear (1)                                            [32, 1280]           [32, 3]              3,843                True\n",
       "============================================================================================================================================\n",
       "Total params: 4,011,391\n",
       "Trainable params: 3,843\n",
       "Non-trainable params: 4,007,548\n",
       "Total mult-adds (Units.GIGABYTES): 12.31\n",
       "============================================================================================================================================\n",
       "Input size (MB): 19.27\n",
       "Forward/backward pass size (MB): 3452.09\n",
       "Params size (MB): 16.05\n",
       "Estimated Total Size (MB): 3487.41\n",
       "============================================================================================================================================"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 4. train a single model and track results",
   "id": "59159ebcbd027628"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-14T18:07:55.512777Z",
     "start_time": "2025-12-14T18:07:55.493795Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define loss function optimizer\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ],
   "id": "5ab632516600912e",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "To track experiments, we're going to use TensorBoard: https://www.tensorflow.org/tensorboard\n",
    "\n",
    "And to interact with IensorBoard, we can use PyTorch's Summarywriter - https:// pytorch.org/docs/stable/tensorboard.html\n",
    "* Also see here: https://pytorch.org/docs/stable/tensorboard.html#torch.utils.tensorboard.writer.Summarywriter"
   ],
   "id": "62c2fc23f8eecc39"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-14T18:07:55.911215Z",
     "start_time": "2025-12-14T18:07:55.514571Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Setup a SummaryWriter\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter()\n",
    "writer"
   ],
   "id": "dac60dd2a21ed3d5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.tensorboard.writer.SummaryWriter at 0x305e2b290>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-14T18:07:55.926095Z",
     "start_time": "2025-12-14T18:07:55.912352Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tqdm.auto import tqdm\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "from going_modular.engine import train_step, test_step\n",
    "\n",
    "def train(model: torch.nn.Module,\n",
    "          train_dataloader: torch.utils.data.DataLoader,\n",
    "          test_dataloader: torch.utils.data.DataLoader,\n",
    "          optimizer: torch.optim.Optimizer,loss_fn: torch.nn.Module,\n",
    "          epochs: int,\n",
    "          device: torch.device,\n",
    "          writer: SummaryWriter = writer) -> Dict[str, List]:\n",
    "    \"\"\"Trains and tests a PyTorch model.\n",
    "\n",
    "    Passes a target PyTorch models through train_step() and test_step()\n",
    "    functions for a number of epochs, training and testing the model\n",
    "    in the same epoch loop.\n",
    "\n",
    "    Calculates, prints and stores evaluation metrics throughout.\n",
    "\n",
    "    Args:\n",
    "        model: A PyTorch model to be trained and tested.\n",
    "        train_dataloader: A DataLoader instance for the model to be trained on.\n",
    "        test_dataloader: A DataLoader instance for the model to be tested on.\n",
    "        optimizer: A PyTorch optimizer to help minimize the loss function.\n",
    "        loss_fn: A PyTorch loss function to calculate loss on both datasets.\n",
    "        epochs: An integer indicating how many epochs to train for.\n",
    "        device: A target device to compute on (e.g. \"cuda\" or \"cpu\").\n",
    "\n",
    "    Returns:\n",
    "        A dictionary of training and testing loss as well as training and\n",
    "        testing accuracy metrics. Each metric has a value in a list for\n",
    "        each epoch.\n",
    "        In the form: {train_loss: [...],\n",
    "        train_acc: [...],\n",
    "        test_loss: [...],\n",
    "        test_acc: [...]}\n",
    "\n",
    "    For example if training for epochs=2:\n",
    "        {train_loss: [2.0616, 1.0537],\n",
    "        train_acc: [0.3945, 0.3945],\n",
    "        test_loss: [1.2641, 1.5706],\n",
    "        test_acc: [0.3400, 0.2973]}\n",
    "    \"\"\"\n",
    "    # Create empty results dictionary\n",
    "    results = {\"train_loss\": [],\n",
    "               \"train_acc\": [],\n",
    "               \"test_loss\": [],\n",
    "               \"test_acc\": []\n",
    "               }\n",
    "\n",
    "    model.to(device)\n",
    "    # Loop through training and testing steps for a number of epochs\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        train_loss, train_acc = train_step(model=model,\n",
    "                                           dataloader=train_dataloader,\n",
    "                                           loss_fn=loss_fn,\n",
    "                                           optimizer=optimizer,\n",
    "                                           device=device)\n",
    "        test_loss, test_acc = test_step(model=model,\n",
    "                                        dataloader=test_dataloader,\n",
    "                                        loss_fn=loss_fn,\n",
    "                                        device=device)\n",
    "\n",
    "        # Print out what's happening\n",
    "        print(f\"Epoch: {epoch+1} | \"\n",
    "              f\"train_loss: {train_loss:.4f} | \"\n",
    "              f\"train_acc: {train_acc:.4f} | \"\n",
    "              f\"test_loss: {test_loss:.4f} | \"\n",
    "              f\"test_acc: {test_acc:.4f}\"\n",
    "              )\n",
    "\n",
    "        # Update results dictionary\n",
    "        results[\"train_loss\"].append(train_loss)\n",
    "        results[\"train_acc\"].append(train_acc)\n",
    "        results[\"test_loss\"].append(test_loss)\n",
    "        results[\"test_acc\"].append(test_acc)\n",
    "\n",
    "\n",
    "        ### New: Experiment tracking\n",
    "        writer.add_scalars(main_tag=\"Loss\",\n",
    "                          tag_scalar_dict={\"train_loss\":train_loss,\n",
    "                                           \"test_loss\": test_loss},\n",
    "                          global_step=epoch)\n",
    "        writer.add_scalars(main_tag=\"Accuracy\",\n",
    "                          tag_scalar_dict={\"train_acc\":train_acc,\n",
    "                                           \"test_acc\": test_acc},\n",
    "                          global_step=epoch)\n",
    "    writer.add_graph(model=model,\n",
    "                     input_to_model=torch.randn(32, 3, 224, 224).to(device))\n",
    "\n",
    "    # Close the writer\n",
    "    writer.close()\n",
    "    ## End new ##\n",
    "\n",
    "    # Return the filled results at the end of the epochs\n",
    "    return results"
   ],
   "id": "c264137383625677",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-14T18:14:23.701589Z",
     "start_time": "2025-12-14T18:07:55.927998Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Train model\n",
    "set_seeds()\n",
    "results = train(model=model,\n",
    "                train_dataloader=train_dataloader,\n",
    "                test_dataloader=test_dataloader,\n",
    "                optimizer=optimizer,\n",
    "                loss_fn=loss_fn,\n",
    "                epochs=5,\n",
    "                device=device)"
   ],
   "id": "ec794d204067b428",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "69e63c1ed89a486cbd05a9870d287575"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | train_loss: 1.0823 | train_acc: 0.4062 | test_loss: 0.8991 | test_acc: 0.5909\n",
      "Epoch: 2 | train_loss: 0.8564 | train_acc: 0.7695 | test_loss: 0.7927 | test_acc: 0.8456\n",
      "Epoch: 3 | train_loss: 0.7914 | train_acc: 0.7891 | test_loss: 0.7373 | test_acc: 0.8561\n",
      "Epoch: 4 | train_loss: 0.7206 | train_acc: 0.7500 | test_loss: 0.6338 | test_acc: 0.8759\n",
      "Epoch: 5 | train_loss: 0.6368 | train_acc: 0.7812 | test_loss: 0.6190 | test_acc: 0.8665\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-14T18:14:23.991764Z",
     "start_time": "2025-12-14T18:14:23.961800Z"
    }
   },
   "cell_type": "code",
   "source": "results",
   "id": "b3be4db1930488",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train_loss': [1.0823059901595116,\n",
       "  0.8563981279730797,\n",
       "  0.791380912065506,\n",
       "  0.7206062972545624,\n",
       "  0.636790856719017],\n",
       " 'train_acc': [0.40625, 0.76953125, 0.7890625, 0.75, 0.78125],\n",
       " 'test_loss': [0.8990757266680399,\n",
       "  0.792700986067454,\n",
       "  0.7373119592666626,\n",
       "  0.6338079373041788,\n",
       "  0.6189916928609213],\n",
       " 'test_acc': [0.5909090909090909,\n",
       "  0.8456439393939394,\n",
       "  0.8560606060606061,\n",
       "  0.8759469696969697,\n",
       "  0.8664772727272728]}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 5. View our models results with TensorBoard\n",
    "\n",
    "There are a few ways to view TensorBoard results:\n",
    "https://www.tensorflow.org/tensorboard/get_started"
   ],
   "id": "12b23e9006f25c13"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-14T18:14:24.042802Z",
     "start_time": "2025-12-14T18:14:23.992339Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import shutil\n",
    "import sys\n",
    "import os\n",
    "\n",
    "print(\"Python:\", sys.executable)\n",
    "print(\"TensorBoard:\", shutil.which(\"tensorboard\"))\n"
   ],
   "id": "c9878f9f5a3de030",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: /opt/anaconda3/bin/python\n",
      "TensorBoard: None\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-14T18:14:24.061068Z",
     "start_time": "2025-12-14T18:14:24.043690Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "tb_path = os.path.join(os.path.dirname(sys.executable), \"tensorboard\")\n",
    "os.environ[\"TENSORBOARD_BINARY\"] = tb_path\n",
    "\n",
    "print(\"Using TensorBoard at:\", tb_path)\n"
   ],
   "id": "ea2680a56952530a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorBoard at: /opt/anaconda3/bin/tensorboard\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-14T18:14:24.132985Z",
     "start_time": "2025-12-14T18:14:24.064493Z"
    }
   },
   "cell_type": "code",
   "source": "%reload_ext tensorboard",
   "id": "ca820dd12bebc963",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-14T18:30:16.335214Z",
     "start_time": "2025-12-14T18:30:13.359621Z"
    }
   },
   "cell_type": "code",
   "source": "%tensorboard --logdir runs",
   "id": "882a8d4149a769a0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-abd2141a564a3bef\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-abd2141a564a3bef\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": "294cf953ca73244de26002d17fffbf4a"
     }
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 6. Create a function to prepare `SummaryWriter()` instance\n",
    "\n",
    "By default, our `SummaryWriter()` class saves to `runs`.\n",
    "\n",
    "How about if we wanted to save different examples to different folders?\n",
    "\n",
    "In essence, one experiment = one folder.\n",
    "\n",
    "For example, we'd like to track:\n",
    "* Experiment date/timestamp\n",
    "* Experiment name\n",
    "* Model name\n",
    "* Extra - is there anything else that should be tracked?\n",
    "\n",
    "Let's create a function to create a `SummaryWriter()` instance to take all of these things into account.\n",
    "\n",
    "So ideally we end up tracking experiments to a directory:\n",
    "\n",
    "`runs/YYYY-MM-DD/experiment_name/model_name/extra`"
   ],
   "id": "186433f51c371067"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-14T18:14:28.530820Z",
     "start_time": "2025-12-14T18:14:28.519484Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "def create_writer(experiment_name: str,\n",
    "                  model_name: str,\n",
    "                  extra: str = None) -> SummaryWriter:\n",
    "    \"\"\"\n",
    "    Creates a torch.utils.tensorboard.SummaryWriter instance tracking to a specific directory.\n",
    "\n",
    "    Args:\n",
    "        experiment_name: The name of the experiment.\n",
    "        model_name: The name of the model.\n",
    "        extra: An optional string to append to the experiment name.\n",
    "\n",
    "    Returns:\n",
    "        A SummaryWriter instance.\n",
    "    \"\"\"\n",
    "    from datetime import datetime\n",
    "    import os\n",
    "\n",
    "    # Get timestamp of current date in reverse order\n",
    "    timestamp = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    if extra:\n",
    "        # Create log directory path\n",
    "        log_dir = os.path.join(\"runs\", timestamp, experiment_name, model_name, extra)\n",
    "    else:\n",
    "        log_dir = os.path.join(\"runs\", timestamp, experiment_name, model_name)\n",
    "\n",
    "    print(f\"[INFO] Created SummaryWriter saving to {log_dir}\")\n",
    "    return SummaryWriter(log_dir=log_dir)"
   ],
   "id": "9cf60f1c88468cc2",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-14T18:14:28.574004Z",
     "start_time": "2025-12-14T18:14:28.565802Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from datetime import datetime\n",
    "timestamp = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "timestamp"
   ],
   "id": "4ad4cb5e1f8ac824",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2025-12-14'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-14T18:14:28.556490Z",
     "start_time": "2025-12-14T18:14:28.535670Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Created SummaryWriter saving to runs/2025-12-14/data_10_percent/effnetb0/5_epochs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch.utils.tensorboard.writer.SummaryWriter at 0x318da6840>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 23,
   "source": [
    "example_writer = create_writer(experiment_name=\"data_10_percent\",\n",
    "                               model_name=\"effnetb0\",\n",
    "                               extra=\"5_epochs\")\n",
    "example_writer"
   ],
   "id": "e9e29f95e436fb9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-14T18:14:28.565340Z",
     "start_time": "2025-12-14T18:14:28.557037Z"
    }
   },
   "cell_type": "markdown",
   "source": "### 6.1 Update the `train()` function to include a writer parameter",
   "id": "b8bade640d99b48"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-14T18:34:55.976786Z",
     "start_time": "2025-12-14T18:34:55.937256Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tqdm.auto import tqdm\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "from going_modular.engine import train_step, test_step\n",
    "\n",
    "def train(model: torch.nn.Module,\n",
    "          train_dataloader: torch.utils.data.DataLoader,\n",
    "          test_dataloader: torch.utils.data.DataLoader,\n",
    "          optimizer: torch.optim.Optimizer,loss_fn: torch.nn.Module,\n",
    "          epochs: int,\n",
    "          device: torch.device,\n",
    "          writer: SummaryWriter = None) -> Dict[str, List]:\n",
    "    \"\"\"Trains and tests a PyTorch model.\n",
    "\n",
    "    Passes a target PyTorch models through train_step() and test_step()\n",
    "    functions for a number of epochs, training and testing the model\n",
    "    in the same epoch loop.\n",
    "\n",
    "    Calculates, prints and stores evaluation metrics throughout.\n",
    "\n",
    "    Args:\n",
    "        model: A PyTorch model to be trained and tested.\n",
    "        train_dataloader: A DataLoader instance for the model to be trained on.\n",
    "        test_dataloader: A DataLoader instance for the model to be tested on.\n",
    "        optimizer: A PyTorch optimizer to help minimize the loss function.\n",
    "        loss_fn: A PyTorch loss function to calculate loss on both datasets.\n",
    "        epochs: An integer indicating how many epochs to train for.\n",
    "        device: A target device to compute on (e.g. \"cuda\" or \"cpu\").\n",
    "\n",
    "    Returns:\n",
    "        A dictionary of training and testing loss as well as training and\n",
    "        testing accuracy metrics. Each metric has a value in a list for\n",
    "        each epoch.\n",
    "        In the form: {train_loss: [...],\n",
    "        train_acc: [...],\n",
    "        test_loss: [...],\n",
    "        test_acc: [...]}\n",
    "\n",
    "    For example if training for epochs=2:\n",
    "        {train_loss: [2.0616, 1.0537],\n",
    "        train_acc: [0.3945, 0.3945],\n",
    "        test_loss: [1.2641, 1.5706],\n",
    "        test_acc: [0.3400, 0.2973]}\n",
    "    \"\"\"\n",
    "    # Create empty results dictionary\n",
    "    results = {\"train_loss\": [],\n",
    "               \"train_acc\": [],\n",
    "               \"test_loss\": [],\n",
    "               \"test_acc\": []\n",
    "               }\n",
    "\n",
    "    model.to(device)\n",
    "    # Loop through training and testing steps for a number of epochs\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        train_loss, train_acc = train_step(model=model,\n",
    "                                           dataloader=train_dataloader,\n",
    "                                           loss_fn=loss_fn,\n",
    "                                           optimizer=optimizer,\n",
    "                                           device=device)\n",
    "        test_loss, test_acc = test_step(model=model,\n",
    "                                        dataloader=test_dataloader,\n",
    "                                        loss_fn=loss_fn,\n",
    "                                        device=device)\n",
    "\n",
    "        # Print out what's happening\n",
    "        print(f\"Epoch: {epoch+1} | \"\n",
    "              f\"train_loss: {train_loss:.4f} | \"\n",
    "              f\"train_acc: {train_acc:.4f} | \"\n",
    "              f\"test_loss: {test_loss:.4f} | \"\n",
    "              f\"test_acc: {test_acc:.4f}\"\n",
    "              )\n",
    "\n",
    "        # Update results dictionary\n",
    "        results[\"train_loss\"].append(train_loss)\n",
    "        results[\"train_acc\"].append(train_acc)\n",
    "        results[\"test_loss\"].append(test_loss)\n",
    "        results[\"test_acc\"].append(test_acc)\n",
    "\n",
    "\n",
    "        ### New: Experiment tracking\n",
    "        if writer:\n",
    "            writer.add_scalars(main_tag=\"Loss\",\n",
    "                               tag_scalar_dict={\"train_loss\":train_loss,\n",
    "                                               \"test_loss\": test_loss},\n",
    "                               global_step=epoch)\n",
    "            writer.add_scalars(main_tag=\"Accuracy\",\n",
    "                               tag_scalar_dict={\"train_acc\":train_acc,\n",
    "                                               \"test_acc\": test_acc},\n",
    "                               global_step=epoch)\n",
    "            writer.add_graph(model=model,\n",
    "                             input_to_model=torch.randn(32, 3, 224, 224).to(device))\n",
    "\n",
    "            # Close the writer\n",
    "            writer.close()\n",
    "    # Return the filled results at the end of the epochs\n",
    "    return results"
   ],
   "id": "1acb6ca24c416dda",
   "outputs": [],
   "execution_count": 34
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 7. Setting up a series of modelling experiments\n",
    "* Challenge: Setup 2x modeling experiments with efnetto, pizza, steak sushi data and train one model for 5 epochs and another model for 10 epochs"
   ],
   "id": "8486fccfa39c8e02"
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-14T18:18:25.021980Z",
     "start_time": "2025-12-14T18:18:24.796073Z"
    }
   },
   "cell_type": "markdown",
   "source": [
    "### 7.1 What kind of experiments should you run?\n",
    "\n",
    "The number of machine learning experiments you can run, is like the number of different models you can build... almost limitless.\n",
    "\n",
    "However, you can't test everything...\n",
    "\n",
    "So what should you test?\n",
    "* Change the number of epochs\n",
    "* Change the number of hidden layers/units\n",
    "* Change the amount of data (right now we're using 10% of the Food101 dataset for pizza, steak, sushi)\n",
    "* Change the learning rate\n",
    "* Try different kinds of data augmentation\n",
    "* Choose a different model architecture\n",
    "\n",
    "This is why transfer learning is powerful, because it's a working model that you can apply to your own problem"
   ],
   "id": "ea185a86777d9bf0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 7.2 What experiments are we going to run?\n",
    "\n",
    "We're going to turn 3 dials:\n",
    "1. Model size - EffnetB0 vs EffnetB2 (in terms of number of params)\n",
    "2. Dataset size - 10% of pizza, steak, sushi images vs 20% (generally more data = better results)\n",
    "3. Training time - 5 epochs vs 10 epochs (generally longer training time = better\n",
    "results... before the model starts to overfit)\n",
    "\n",
    "To begin, we're still keeping things relatively small so that our experiments run quickly."
   ],
   "id": "a898758441c50957"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "891a890bd4c4e8e4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-14T19:07:03.314470Z",
     "start_time": "2025-12-14T19:07:02.684703Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from Progress.course_progress_func import update_progress, progress_pie_chart, monthly_progress, progress_report_print\n",
    "update_progress(video_index=213, done=True)"
   ],
   "id": "805b4d2a3757ab1d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m\u001B[92mUpdated progress report.\u001B[0m \n",
      "\u001B[1mVideo:\u001B[0m 212. Discussing the Experiments We Are Going to Try \n",
      "\u001B[1mDuration:\u001B[0m 6m \n",
      "\u001B[1mStatus:\u001B[0m Done \n",
      "\u001B[1mDate:\u001B[0m 14 Dec 2025 09:07 PM \n",
      "\u001B[1mSection progress:\u001B[0m \n",
      "\u001B[1mSection :\u001B[0m 9.PyTorch Experiment Tracking\n",
      "\u001B[1mStatus  :\u001B[0m 9 videos remaining, 1h 22m to finish the section\n",
      "\u001B[1mProgress: \u001B[0m 59%|\u001B[34m█████████████████▏           \u001B[0m 13/22\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-14T19:07:15.787748Z",
     "start_time": "2025-12-14T19:07:15.206167Z"
    }
   },
   "cell_type": "code",
   "source": "progress_report_print()",
   "id": "58976d7d407a9cca",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m\u001B[94m      ___         ___           ___           ___           ___           ___           ___           ___     \n",
      "     /  /\\       /  /\\         /  /\\         /  /\\         /  /\\         /  /\\         /  /\\         /  /\\    \n",
      "    /  /::\\     /  /::\\       /  /::\\       /  /:/_       /  /::\\       /  /:/_       /  /:/_       /  /:/_   \n",
      "   /  /:/\\:\\   /  /:/\\:\\     /  /:/\\:\\     /  /:/ /\\     /  /:/\\:\\     /  /:/ /\\     /  /:/ /\\     /  /:/ /\\  \n",
      "  /  /:/~/:/  /  /:/~/:/    /  /:/  \\:\\   /  /:/_/::\\   /  /:/~/:/    /  /:/ /:/_   /  /:/ /::\\   /  /:/ /::\\ \n",
      " /__/:/ /:/  /__/:/ /:/___ /__/:/ \\__\\:\\ /__/:/__\\/\\:\\ /__/:/ /:/___ /__/:/ /:/ /\\ /__/:/ /:/\\:\\ /__/:/ /:/\\:\\\n",
      " \\  \\:\\/:/   \\  \\:\\/:::::/ \\  \\:\\ /  /:/ \\  \\:\\ /~~/:/ \\  \\:\\/:::::/ \\  \\:\\/:/ /:/ \\  \\:\\/:/~/:/ \\  \\:\\/:/~/:/\n",
      "  \\  \\::/     \\  \\::/~~~~   \\  \\:\\  /:/   \\  \\:\\  /:/   \\  \\::/~~~~   \\  \\::/ /:/   \\  \\::/ /:/   \\  \\::/ /:/ \n",
      "   \\  \\:\\      \\  \\:\\        \\  \\:\\/:/     \\  \\:\\/:/     \\  \\:\\        \\  \\:\\/:/     \\__\\/ /:/     \\__\\/ /:/  \n",
      "    \\  \\:\\      \\  \\:\\        \\  \\::/       \\  \\::/       \\  \\:\\        \\  \\::/        /__/:/        /__/:/   \n",
      "     \\__\\/       \\__\\/         \\__\\/         \\__\\/         \\__\\/         \\__\\/         \\__\\/         \\__\\/    \n",
      "      ___           ___           ___         ___           ___                 \n",
      "     /  /\\         /  /\\         /  /\\       /  /\\         /  /\\          ___   \n",
      "    /  /::\\       /  /:/_       /  /::\\     /  /::\\       /  /::\\        /  /\\  \n",
      "   /  /:/\\:\\     /  /:/ /\\     /  /:/\\:\\   /  /:/\\:\\     /  /:/\\:\\      /  /:/  \n",
      "  /  /:/~/:/    /  /:/ /:/_   /  /:/~/:/  /  /:/  \\:\\   /  /:/~/:/     /  /:/   \n",
      " /__/:/ /:/___ /__/:/ /:/ /\\ /__/:/ /:/  /__/:/ \\__\\:\\ /__/:/ /:/___  /  /::\\   \n",
      " \\  \\:\\/:::::/ \\  \\:\\/:/ /:/ \\  \\:\\/:/   \\  \\:\\ /  /:/ \\  \\:\\/:::::/ /__/:/\\:\\  \n",
      "  \\  \\::/~~~~   \\  \\::/ /:/   \\  \\::/     \\  \\:\\  /:/   \\  \\::/~~~~  \\__\\/  \\:\\ \n",
      "   \\  \\:\\        \\  \\:\\/:/     \\  \\:\\      \\  \\:\\/:/     \\  \\:\\           \\  \\:\\\n",
      "    \\  \\:\\        \\  \\::/       \\  \\:\\      \\  \\::/       \\  \\:\\           \\__\\/\n",
      "     \\__\\/         \\__\\/         \\__\\/       \\__\\/         \\__\\/                \n",
      "\u001B[0m\n",
      "\u001B[1m\u001B[93mCourse:\u001B[0m  73%|\u001B[34m███████████████████▊       \u001B[0m 263/358\u001B[0m\n",
      "\u001B[1m\u001B[93mTotal time done:\u001B[0m 40h 1m out of 52h 15m watched (12h 14m remaining).\n",
      "\u001B[1m\u001B[93mTotal videos done:\u001B[0m 263 out of 358 finished (95 videos remaining).\n",
      "\n",
      "\u001B[1mSection :\u001B[0m 1.Introduction\n",
      "\u001B[1mStatus  :\u001B[0m \u001B[92mDone (7 videos | Total Duration: 22m)\u001B[0m\n",
      "\u001B[1mProgress: \u001B[0m100%|\u001B[34m███████████████████████████████\u001B[0m 7/7\u001B[0m\n",
      "\n",
      "\u001B[1mSection :\u001B[0m 2.PyTorch Fundamentals\n",
      "\u001B[1mStatus  :\u001B[0m \u001B[92mDone (32 videos | Total Duration: 4h 9m)\u001B[0m\n",
      "\u001B[1mProgress: \u001B[0m100%|\u001B[34m█████████████████████████████\u001B[0m 32/32\u001B[0m\n",
      "\n",
      "\u001B[1mSection :\u001B[0m 3.PyTorch Workflow\n",
      "\u001B[1mStatus  :\u001B[0m \u001B[92mDone (28 videos | Total Duration: 4h 17m)\u001B[0m\n",
      "\u001B[1mProgress: \u001B[0m100%|\u001B[34m█████████████████████████████\u001B[0m 28/28\u001B[0m\n",
      "\n",
      "\u001B[1mSection :\u001B[0m 4.PyTorch Neural Network Classification\n",
      "\u001B[1mStatus  :\u001B[0m \u001B[92mDone (32 videos | Total Duration: 5h 26m)\u001B[0m\n",
      "\u001B[1mProgress: \u001B[0m100%|\u001B[34m█████████████████████████████\u001B[0m 32/32\u001B[0m\n",
      "\n",
      "\u001B[1mSection :\u001B[0m 5.PyTorch Computer Vision\n",
      "\u001B[1mStatus  :\u001B[0m \u001B[92mDone (34 videos | Total Duration: 5h 42m)\u001B[0m\n",
      "\u001B[1mProgress: \u001B[0m100%|\u001B[34m█████████████████████████████\u001B[0m 34/34\u001B[0m\n",
      "\n",
      "\u001B[1mSection :\u001B[0m 6.PyTorch Custom Datasets\n",
      "\u001B[1mStatus  :\u001B[0m \u001B[92mDone (37 videos | Total Duration: 5h 51m)\u001B[0m\n",
      "\u001B[1mProgress: \u001B[0m100%|\u001B[34m█████████████████████████████\u001B[0m 37/37\u001B[0m\n",
      "\n",
      "\u001B[1mSection :\u001B[0m 7.PyTorch Going Modular\n",
      "\u001B[1mStatus  :\u001B[0m \u001B[92mDone (10 videos | Total Duration: 1h 33m)\u001B[0m\n",
      "\u001B[1mProgress: \u001B[0m100%|\u001B[34m█████████████████████████████\u001B[0m 10/10\u001B[0m\n",
      "\n",
      "\u001B[1mSection :\u001B[0m 8.PyTorch Transfer Learning\n",
      "\u001B[1mStatus  :\u001B[0m \u001B[92mDone (19 videos | Total Duration: 2h 44m)\u001B[0m\n",
      "\u001B[1mProgress: \u001B[0m100%|\u001B[34m█████████████████████████████\u001B[0m 19/19\u001B[0m\n",
      "\n",
      "\u001B[1mSection :\u001B[0m 9.PyTorch Experiment Tracking\n",
      "\u001B[1mStatus  :\u001B[0m 9 videos remaining, 1h 22m to finish the section\n",
      "\u001B[1mProgress: \u001B[0m 59%|\u001B[34m█████████████████▏           \u001B[0m 13/22\u001B[0m\n",
      "\n",
      "\u001B[1mSection :\u001B[0m 10.PyTorch Paper Replicating (Skipped for now)\n",
      "\u001B[1mStatus  :\u001B[0m \u001B[92mDone (50 videos | Total Duration: 8h 7m)\u001B[0m\n",
      "\u001B[1mProgress: \u001B[0m100%|\u001B[34m█████████████████████████████\u001B[0m 50/50\u001B[0m\n",
      "\n",
      "\u001B[1mSection :\u001B[0m 11.PyTorch Model Deployment\n",
      "\u001B[1mStatus  :\u001B[0m 57 videos remaining, 7h 45m to finish the section\n",
      "\u001B[1mProgress: \u001B[0m  0%|\u001B[34m                              \u001B[0m 0/57\u001B[0m\n",
      "\n",
      "\u001B[1mSection :\u001B[0m 12.Introduction to PyTorch 2.0 and torch.compile\n",
      "\u001B[1mStatus  :\u001B[0m 25 videos remaining, 3h 3m to finish the section\n",
      "\u001B[1mProgress: \u001B[0m  0%|\u001B[34m                              \u001B[0m 0/25\u001B[0m\n",
      "\n",
      "\u001B[1mSection :\u001B[0m 13.Bonus Section\n",
      "\u001B[1mStatus  :\u001B[0m \u001B[92mDone (1 video | Total Duration: 1m)\u001B[0m\n",
      "\u001B[1mProgress: \u001B[0m100%|\u001B[34m███████████████████████████████\u001B[0m 1/1\u001B[0m\n",
      "\n",
      "\u001B[1mSection :\u001B[0m 14.Where To Go From Here?\n",
      "\u001B[1mStatus  :\u001B[0m 4 videos remaining, 4m to finish the section\n",
      "\u001B[1mProgress: \u001B[0m  0%|\u001B[34m                               \u001B[0m 0/4\u001B[0m\n",
      "\n"
     ]
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "da9c015e79441a90"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
